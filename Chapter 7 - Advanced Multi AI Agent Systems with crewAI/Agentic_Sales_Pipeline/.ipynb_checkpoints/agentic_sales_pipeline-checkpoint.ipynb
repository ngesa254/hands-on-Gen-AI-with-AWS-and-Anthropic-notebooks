{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7591c5b0-c58c-419e-b5ab-0536dfbc9369",
   "metadata": {},
   "source": [
    "# CH 7: Agentic Sales Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d796a712-bd22-47fb-bf11-3b17ec777250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU crewai==0.75 crewai_tools==0.13.2 langchain_community==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "533f8486-0a0b-4296-9b05-b32003262f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcce6de-1ba1-4a17-a8b9-8dc14ee0ba72",
   "metadata": {},
   "source": [
    "## Import libraries, API and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f349df-c1ae-4d3a-a9f6-336d79c4bba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from utils import get_bedrock_client, get_haiku_config, get_sonnet_config\n",
    "from langchain_community.chat_models import BedrockChat  # Changed this import\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d836ea2-28e6-418b-a9d0-16e510027119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from utils import get_openai_api_key\n",
    "\n",
    "# openai_api_key = get_openai_api_key()\n",
    "# os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
    "\n",
    "\n",
    "bedrock_client = get_bedrock_client()\n",
    "sonnet_config = get_sonnet_config()  # Using Sonnet config\n",
    "\n",
    "# Create BedrockChat instance for CrewAI\n",
    "llm = BedrockChat(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # Updated model ID\n",
    "    streaming=True,\n",
    "    model_kwargs={\n",
    "        \"temperature\": sonnet_config[\"temperature\"],\n",
    "        \"top_p\": sonnet_config[\"top_p\"],\n",
    "        \"max_tokens\": sonnet_config[\"max_tokens\"],\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set model name in environment if needed\n",
    "os.environ[\"MODEL_NAME\"] = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60b2d6-1ca8-4a49-9c17-ca71750cb889",
   "metadata": {},
   "source": [
    "## Loading Tasks and Agents YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4645a4-bc3e-492a-9e09-93cb4703d83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'lead_agents': 'config/lead_qualification_agents.yaml',\n",
    "    'lead_tasks': 'config/lead_qualification_tasks.yaml',\n",
    "    'email_agents': 'config/email_engagement_agents.yaml',\n",
    "    'email_tasks': 'config/email_engagement_tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "lead_agents_config = configs['lead_agents']\n",
    "lead_tasks_config = configs['lead_tasks']\n",
    "email_agents_config = configs['email_agents']\n",
    "email_tasks_config = configs['email_tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbcab3-7fb2-48bc-804b-95c9e0eaa221",
   "metadata": {},
   "source": [
    "## Create Pydantic Models for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b41111b5-818c-469a-b7a3-02458c1e9b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Optional, List, Set, Tuple\n",
    "\n",
    "class LeadPersonalInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The full name of the lead.\")\n",
    "    job_title: str = Field(..., description=\"The job title of the lead.\")\n",
    "    role_relevance: int = Field(..., ge=0, le=10, description=\"A score representing how relevant the lead's role is to the decision-making process (0-10).\")\n",
    "    professional_background: Optional[str] = Field(..., description=\"A brief description of the lead's professional background.\")\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    company_name: str = Field(..., description=\"The name of the company the lead works for.\")\n",
    "    industry: str = Field(..., description=\"The industry in which the company operates.\")\n",
    "    company_size: int = Field(..., description=\"The size of the company in terms of employee count.\")\n",
    "    revenue: Optional[float] = Field(None, description=\"The annual revenue of the company, if available.\")\n",
    "    market_presence: int = Field(..., ge=0, le=10, description=\"A score representing the company's market presence (0-10).\")\n",
    "\n",
    "class LeadScore(BaseModel):\n",
    "    score: int = Field(..., ge=0, le=100, description=\"The final score assigned to the lead (0-100).\")\n",
    "    scoring_criteria: List[str] = Field(..., description=\"The criteria used to determine the lead's score.\")\n",
    "    validation_notes: Optional[str] = Field(None, description=\"Any notes regarding the validation of the lead score.\")\n",
    "\n",
    "class LeadScoringResult(BaseModel):\n",
    "    personal_info: LeadPersonalInfo = Field(..., description=\"Personal information about the lead.\")\n",
    "    company_info: CompanyInfo = Field(..., description=\"Information about the lead's company.\")\n",
    "    lead_score: LeadScore = Field(..., description=\"The calculated score and related information for the lead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba03ea-dd23-479d-9974-37165e28c068",
   "metadata": {},
   "source": [
    "## Importing Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9863116-43a8-4c19-9ae1-e4f725c835c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a65a0d-c054-48ec-8cc5-0530de07d535",
   "metadata": {},
   "source": [
    "## Lead Qualification Crew, Agents and Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e7b340e-e7bd-4cee-86dc-4fca70ea6fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 11:23:12,572 - 140250410932032 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "lead_data_agent = Agent(\n",
    "  config=lead_agents_config['lead_data_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "cultural_fit_agent = Agent(\n",
    "  config=lead_agents_config['cultural_fit_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "scoring_validation_agent = Agent(\n",
    "  config=lead_agents_config['scoring_validation_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "lead_data_task = Task(\n",
    "  config=lead_tasks_config['lead_data_collection'],\n",
    "  agent=lead_data_agent\n",
    ")\n",
    "\n",
    "cultural_fit_task = Task(\n",
    "  config=lead_tasks_config['cultural_fit_analysis'],\n",
    "  agent=cultural_fit_agent\n",
    ")\n",
    "\n",
    "scoring_validation_task = Task(\n",
    "  config=lead_tasks_config['lead_scoring_and_validation'],\n",
    "  agent=scoring_validation_agent,\n",
    "  context=[lead_data_task, cultural_fit_task],\n",
    "  output_pydantic=LeadScoringResult\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "lead_scoring_crew = Crew(\n",
    "  agents=[\n",
    "    lead_data_agent,\n",
    "    cultural_fit_agent,\n",
    "    scoring_validation_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    lead_data_task,\n",
    "    cultural_fit_task,\n",
    "    scoring_validation_task\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa96f6-b87c-492e-a0dd-22021b9a0792",
   "metadata": {},
   "source": [
    "## Email Engagement Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9acf3204-738b-4fe8-8794-8f50caade346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 11:23:14,202 - 140250410932032 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "email_content_specialist = Agent(\n",
    "  config=email_agents_config['email_content_specialist'],\n",
    "    llm=llm\n",
    "    \n",
    ")\n",
    "\n",
    "engagement_strategist = Agent(\n",
    "  config=email_agents_config['engagement_strategist'],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "email_drafting = Task(\n",
    "  config=email_tasks_config['email_drafting'],\n",
    "  agent=email_content_specialist,\n",
    "    \n",
    ")\n",
    "\n",
    "engagement_optimization = Task(\n",
    "  config=email_tasks_config['engagement_optimization'],\n",
    "  agent=engagement_strategist\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "email_writing_crew = Crew(\n",
    "  agents=[\n",
    "    email_content_specialist,\n",
    "    engagement_strategist\n",
    "  ],\n",
    "  tasks=[\n",
    "    email_drafting,\n",
    "    engagement_optimization\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa770b-ba0a-45bc-a5d6-690ece486362",
   "metadata": {},
   "source": [
    "## Creating Complete Sales Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75c7019c-c249-48d9-a940-19c4e2707cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, start\n",
    "\n",
    "class SalesPipeline(Flow):\n",
    "    @start()\n",
    "    def fetch_leads(self):\n",
    "        # Pull our leads from the database\n",
    "        leads = [\n",
    "            {\n",
    "                \"lead_data\": {\n",
    "                    \"name\": \"João Moura\",\n",
    "                    \"job_title\": \"Director of Engineering\",\n",
    "                    \"company\": \"Clearbit\",\n",
    "                    \"email\": \"joao@clearbit.com\",\n",
    "                    \"use_case\": \"Using AI Agent to do better data enrichment.\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "        return leads\n",
    "\n",
    "    @listen(fetch_leads)\n",
    "    def score_leads(self, leads):\n",
    "        scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "        self.state[\"score_crews_results\"] = scores\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def store_leads_score(self, scores):\n",
    "        # Here we would store the scores in the database\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def filter_leads(self, scores):\n",
    "        return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "    @listen(filter_leads)\n",
    "    def write_email(self, leads):\n",
    "        scored_leads = [lead.to_dict() for lead in leads]\n",
    "        emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "        return emails\n",
    "\n",
    "    @listen(write_email)\n",
    "    def send_email(self, emails):\n",
    "        # Here we would send the emails to the leads\n",
    "        return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5554b0-007c-4e12-9a4e-3806141bf93f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Telemetry' object has no attribute 'flow_creation_span'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mSalesPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/flow/flow.py:166\u001b[0m, in \u001b[0;36mFlow.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_and_listeners: Dict[\u001b[38;5;28mstr\u001b[39m, Set[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method_outputs: List[Any] \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store all method outputs\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_telemetry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_creation_span\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m method_name\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     ):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Telemetry' object has no attribute 'flow_creation_span'"
     ]
    }
   ],
   "source": [
    "flow = SalesPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79660b0e-f9d1-40a8-ab3f-eeae15e7c201",
   "metadata": {},
   "source": [
    "## Plotting the Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d465dc3-4f3e-4c07-8dd3-9588ab2b8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e66435-1aa3-4f4b-8a92-b5d813b94853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98e89a-2fc5-4eb9-a9e9-d0dc1ef17d0a",
   "metadata": {},
   "source": [
    "## Flow Kickoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7225ced-c86a-41b0-b381-9649019d30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = await flow.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961a05b-09be-413c-b2ec-a828365aadbb",
   "metadata": {},
   "source": [
    "## Usage Metrics and Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006e09f-2e75-434f-aa62-658030314217",
   "metadata": {},
   "source": [
    "Let’s see how much it would cost each time if this crew runs at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7512151-976d-4c8a-b776-509b21e76a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([flow.state[\"score_crews_results\"][0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "costs = 0.150 * df_usage_metrics['total_tokens'].sum() / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a4c45-a124-4631-8f22-c759f91d38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([emails[0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "costs = 0.150 * df_usage_metrics['total_tokens'].sum() / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b24c6d-4c80-49d6-bbab-8dc8770477b4",
   "metadata": {},
   "source": [
    "## Inspecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb6d247f-0a91-4c61-8d9d-f0235ad9e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_crews_results\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow' is not defined"
     ]
    }
   ],
   "source": [
    "scores = flow.state[\"score_crews_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e471987-0fd5-4f21-872d-8ec5fd872732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "lead_scoring_result = scores[0].pydantic\n",
    "\n",
    "# Create a dictionary with the nested structure flattened\n",
    "data = {\n",
    "    'Name': lead_scoring_result.personal_info.name,\n",
    "    'Job Title': lead_scoring_result.personal_info.job_title,\n",
    "    'Role Relevance': lead_scoring_result.personal_info.role_relevance,\n",
    "    'Professional Background': lead_scoring_result.personal_info.professional_background,\n",
    "    'Company Name': lead_scoring_result.company_info.company_name,\n",
    "    'Industry': lead_scoring_result.company_info.industry,\n",
    "    'Company Size': lead_scoring_result.company_info.company_size,\n",
    "    'Revenue': lead_scoring_result.company_info.revenue,\n",
    "    'Market Presence': lead_scoring_result.company_info.market_presence,\n",
    "    'Lead Score': lead_scoring_result.lead_score.score,\n",
    "    'Scoring Criteria': ', '.join(lead_scoring_result.lead_score.scoring_criteria),\n",
    "    'Validation Notes': lead_scoring_result.lead_score.validation_notes\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient='index', columns=['Value'])\n",
    "\n",
    "# Reset the index to turn the original column names into a regular column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Rename the index column to 'Attribute'\n",
    "df = df.rename(columns={'index': 'Attribute'})\n",
    "\n",
    "# Create HTML table with bold attributes and left-aligned values\n",
    "html_table = df.style.set_properties(**{'text-align': 'left'}) \\\n",
    "                     .format({'Attribute': lambda x: f'<b>{x}</b>'}) \\\n",
    "                     .hide(axis='index') \\\n",
    "                     .to_html()\n",
    "\n",
    "# Display the styled HTML table\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd684a3c-8782-44e8-9cdc-3ec02cd01ad6",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a82edf1-2be6-4c81-86c1-a8ac3baa9231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m result_text \u001b[38;5;241m=\u001b[39m \u001b[43memails\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mraw\n\u001b[1;32m      4\u001b[0m wrapped_text \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mfill(result_text, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(wrapped_text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "result_text = emails[0].raw\n",
    "wrapped_text = textwrap.fill(result_text, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b7954-de24-4cb3-9f10-72e816dcedc5",
   "metadata": {},
   "source": [
    "## How Complex Can it Get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "771781dd-e294-4fab-8c69-e5626cc8a224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Flow' from 'crewai' (/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flow\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m listen, start, and_, or_, router\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSalesPipeline\u001b[39;00m(Flow):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Flow' from 'crewai' (/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from crewai import Flow\n",
    "from crewai.flow.flow import listen, start, and_, or_, router\n",
    "\n",
    "class SalesPipeline(Flow):\n",
    "    \n",
    "  @start()\n",
    "  def fetch_leads(self):\n",
    "    # Pull our leads from the database\n",
    "    # This is a mock, in a real-world scenario, this is where you would\n",
    "    # fetch leads from a database\n",
    "    leads = [\n",
    "      {\n",
    "        \"lead_data\": {\n",
    "          \"name\": \"João Moura\",\n",
    "          \"job_title\": \"Director of Engineering\",\n",
    "          \"company\": \"Clearbit\",\n",
    "          \"email\": \"joao@clearbit.com\",\n",
    "          \"use_case\": \"Using AI Agent to do better data enrichment.\"\n",
    "        },\n",
    "      },\n",
    "    ]\n",
    "    return leads\n",
    "\n",
    "  @listen(fetch_leads)\n",
    "  def score_leads(self, leads):\n",
    "    scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "    self.state[\"score_crews_results\"] = scores\n",
    "    return scores\n",
    "\n",
    "  @listen(score_leads)\n",
    "  def store_leads_score(self, scores):\n",
    "    # Here we would store the scores in the database\n",
    "    return scores\n",
    "\n",
    "  @listen(score_leads)\n",
    "  def filter_leads(self, scores):\n",
    "    return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "  @listen(and_(filter_leads, store_leads_score))\n",
    "  def log_leads(self, leads):\n",
    "    print(f\"Leads: {leads}\")\n",
    "\n",
    "  @router(filter_leads, paths=[\"high\", \"medium\", \"low\"])\n",
    "  def count_leads(self, scores):\n",
    "    if len(scores) > 10:\n",
    "      return 'high'\n",
    "    elif len(scores) > 5:\n",
    "      return 'medium'\n",
    "    else:\n",
    "      return 'low'\n",
    "\n",
    "  @listen('high')\n",
    "  def store_in_salesforce(self, leads):\n",
    "    return leads\n",
    "\n",
    "  @listen('medium')\n",
    "  def send_to_sales_team(self, leads):\n",
    "    return leads\n",
    "\n",
    "  @listen('low')\n",
    "  def write_email(self, leads):\n",
    "    scored_leads = [lead.to_dict() for lead in leads]\n",
    "    emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "    return emails\n",
    "\n",
    "  @listen(write_email)\n",
    "  def send_email(self, emails):\n",
    "    # Here we would send the emails to the leads\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5cff1-f718-4633-a6c4-dd46cdae9054",
   "metadata": {},
   "source": [
    "## Plotting the Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccbfdb38-4ec1-48c9-888c-9f2be66400a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Telemetry' object has no attribute 'flow_creation_span'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mSalesPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m flow\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/flow/flow.py:166\u001b[0m, in \u001b[0;36mFlow.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_and_listeners: Dict[\u001b[38;5;28mstr\u001b[39m, Set[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method_outputs: List[Any] \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store all method outputs\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_telemetry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_creation_span\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m method_name\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     ):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Telemetry' object has no attribute 'flow_creation_span'"
     ]
    }
   ],
   "source": [
    "flow = SalesPipeline()\n",
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4cba6f3-8c8c-4e5d-8f57-a49d84fd68f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"150%\"\n",
       "            height=\"600\"\n",
       "            src=\"./crewai_flow_complex.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e5b112c20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='./crewai_flow_complex.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6168b-c140-4c4d-b43c-4c7e2e61e24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
