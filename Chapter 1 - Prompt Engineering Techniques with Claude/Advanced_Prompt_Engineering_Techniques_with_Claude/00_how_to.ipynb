{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c492bd-7bb0-49d8-aebc-4ed05b5dd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1a2645-5363-4aa6-ba29-e6db7ad0495b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d983e4a4-3965-44b1-afae-3712e81de5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_bedrock_client, get_haiku_config, get_sonnet_config\n",
    "from langchain_community.chat_models import BedrockChat  # Changed this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b8b075-6fdb-42e0-99e4-b57c5a40c1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = get_bedrock_client()\n",
    "sonnet_config = get_sonnet_config()  # Using Sonnet config\n",
    "\n",
    "# Create BedrockChat instance for CrewAI\n",
    "llm = BedrockChat(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # Updated model ID\n",
    "    streaming=True,\n",
    "    model_kwargs={\n",
    "        \"temperature\": sonnet_config[\"temperature\"],\n",
    "        \"top_p\": sonnet_config[\"top_p\"],\n",
    "        \"max_tokens\": sonnet_config[\"max_tokens\"],\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set model name in environment if needed\n",
    "os.environ[\"MODEL_NAME\"] = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5e19f-00e0-41cc-a496-fb905e09d3f0",
   "metadata": {},
   "source": [
    "Let us create get_completion, which is a helper function that sends a prompt to Claude and returns Claude's generated response. Run that cell now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bede4a05-0c26-4d5b-b576-daff7224a0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError  # Import ClientError for exception handling\n",
    "\n",
    "def get_completion(prompt, system_prompt=None):\n",
    "    \"\"\"\n",
    "    Helper function to get a completion from the Bedrock client.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt to provide to the model.\n",
    "        system_prompt (str, optional): An optional system prompt to set context for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the model.\n",
    "    \"\"\"\n",
    "    # Use existing configurations for inference and model parameters\n",
    "    inference_config = {\n",
    "        \"temperature\": 0.0,  # Minimal randomness\n",
    "        \"maxTokens\": 200  # Maximum token limit\n",
    "    }\n",
    "    additional_model_fields = {\n",
    "        \"top_p\": 1  # Full probability distribution\n",
    "    }\n",
    "\n",
    "    # Build the message structure, including system prompt in the user prompt context\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": f\"{system_prompt}\\n{prompt}\" if system_prompt else prompt}]}]\n",
    "\n",
    "    # Set up the Bedrock client request\n",
    "    converse_api_params = {\n",
    "        \"modelId\": sonnet_config[\"model\"],  # Use the model ID from sonnet_config\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": inference_config,\n",
    "        \"additionalModelRequestFields\": additional_model_fields\n",
    "    }\n",
    "\n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = bedrock_client.converse(**converse_api_params)\n",
    "        # Extract and return the generated content\n",
    "        return response['output']['message']['content'][0]['text']\n",
    "\n",
    "    except ClientError as err:\n",
    "        print(f\"Client error occurred: {err.response['Error']['Message']}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b513dc4d-2507-41ac-9c6b-b6d53e6fa07c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) has become a game-changer in the modern business landscape, revolutionizing various aspects of operations and decision-making processes. The significance of AI in modern business can be highlighted through the following points:\n",
      "\n",
      "1. Automation and Efficiency: AI enables businesses to automate repetitive and time-consuming tasks, leading to increased efficiency, reduced costs, and improved productivity. From automating customer service through chatbots to streamlining supply chain management, AI can optimize processes and free up human resources for more strategic and creative endeavors.\n",
      "\n",
      "2. Data Analysis and Insights: AI excels at processing and analyzing vast amounts of data, enabling businesses to uncover valuable insights and patterns that would be difficult or impossible for humans to detect. This data-driven decision-making can lead to better strategic planning, targeted marketing campaigns, and personalized customer experiences.\n",
      "\n",
      "3. Predictive Analytics: AI algorithms can analyze historical data and current trends to make\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\n",
    "    prompt=\"Explain the significance of AI in modern business.\",\n",
    "    system_prompt=\"You are an expert in AI and its applications in business.\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6989eb5-1f31-40bc-b3be-9925344d3171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "prompt = \"Hello, Claude!\"\n",
    "\n",
    "# Get Claude's response\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9742aa-c513-4847-a6f8-0a2cf5c4a12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
