{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe4fb8e-c0de-46b8-8e9b-390b112b5005",
   "metadata": {},
   "source": [
    "# CH 6: Multi-agent Customer Support Automation\n",
    "\n",
    "In this lesson, you will learn about the six key elements which help make Agents perform even better:\n",
    "- Role Playing\n",
    "- Focus\n",
    "- Tools\n",
    "- Cooperation\n",
    "- Guardrails\n",
    "- Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5ed418-3d62-4c49-a58e-8b886d01011a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fabd07-a7e2-4979-8172-6a6aa9c87dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6af2ba-03b4-466b-9e05-c089e5c393d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_bedrock_client, get_haiku_config, get_sonnet_config\n",
    "from langchain_community.chat_models import BedrockChat  # Changed this import\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb9fd59-c691-4be2-ad12-9d95ca891973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from utils import get_openai_api_key\n",
    "\n",
    "# openai_api_key = get_openai_api_key()\n",
    "# os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
    "\n",
    "\n",
    "bedrock_client = get_bedrock_client()\n",
    "sonnet_config = get_sonnet_config()  # Using Sonnet config\n",
    "\n",
    "# Create BedrockChat instance for CrewAI\n",
    "llm = BedrockChat(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # Updated model ID\n",
    "    streaming=True,\n",
    "    model_kwargs={\n",
    "        \"temperature\": sonnet_config[\"temperature\"],\n",
    "        \"top_p\": sonnet_config[\"top_p\"],\n",
    "        \"max_tokens\": sonnet_config[\"max_tokens\"],\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set model name in environment if needed\n",
    "os.environ[\"MODEL_NAME\"] = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbeaae-37fa-411d-814f-379e9b8b26a2",
   "metadata": {},
   "source": [
    "## Import libraries, API and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7451f5-3eb1-4eb1-8d84-09c89372d5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c3164-ff25-4c11-ab1b-70173383f4c6",
   "metadata": {},
   "source": [
    "## Role Playing, Focus and Cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ae1aa3-dc6a-4de5-aae9-b2bb6a3bc94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "support_agent = Agent(\n",
    "    role=\"Senior Support Representative\",\n",
    "\tgoal=\"Be the most friendly and helpful \"\n",
    "        \"support representative in your team\",\n",
    "\tbackstory=(\n",
    "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
    "        \" are now working on providing \"\n",
    "\t\t\"support to {customer}, a super important customer \"\n",
    "        \" for your company.\"\n",
    "\t\t\"You need to make sure that you provide the best support!\"\n",
    "\t\t\"Make sure to provide full complete answers, \"\n",
    "        \" and make no assumptions.\"\n",
    "\t),\n",
    "\tallow_delegation=False,\n",
    "\tverbose=True,\n",
    "     llm=llm,\n",
    "     max_iter=5,\n",
    "    memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a4afb-ee1d-4903-9c37-0dae42399811",
   "metadata": {},
   "source": [
    "- By not setting `allow_delegation=False`, `allow_delegation` takes its default value of being `True`.\n",
    "- This means the agent _can_ delegate its work to another agent which is better suited to do a particular task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28528008-37dc-4a7a-bae1-fc38434b73f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "support_quality_assurance_agent = Agent(\n",
    "\trole=\"Support Quality Assurance Specialist\",\n",
    "\tgoal=\"Get recognition for providing the \"\n",
    "    \"best support quality assurance in your team\",\n",
    "\tbackstory=(\n",
    "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
    "        \"are now working with your team \"\n",
    "\t\t\"on a request from {customer} ensuring that \"\n",
    "        \"the support representative is \"\n",
    "\t\t\"providing the best support possible.\\n\"\n",
    "\t\t\"You need to make sure that the support representative \"\n",
    "        \"is providing full\"\n",
    "\t\t\"complete answers, and make no assumptions.\"\n",
    "\t),\n",
    "\tverbose=True,\n",
    "    llm=llm,\n",
    "     max_iter=5,\n",
    "    memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c279401-e4d3-4a2e-ad98-85dd4a2c8607",
   "metadata": {
    "tags": []
   },
   "source": [
    "* **Role Playing**: Both agents have been given a role, goal and backstory.\n",
    "* **Focus**: Both agents have been prompted to get into the character of the roles they are playing.\n",
    "* **Cooperation**: Support Quality Assurance Agent can delegate work back to the Support Agent, allowing for these agents to work together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f51ca8-7f18-4848-8c84-c80d5be08071",
   "metadata": {},
   "source": [
    "## Tools, Guardrails and Memory\n",
    "\n",
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53ed47-c8f3-4c6a-b80d-e78f4a0c398b",
   "metadata": {},
   "source": [
    "- Import CrewAI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2c34d18-1a06-4e59-adee-a36955399d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool, \\\n",
    "                         ScrapeWebsiteTool, \\\n",
    "                         WebsiteSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a50c5-d6ba-4750-a03d-512df578585b",
   "metadata": {},
   "source": [
    "### Possible Custom Tools\n",
    "- Load customer data\n",
    "- Tap into previous conversations\n",
    "- Load data from a CRM\n",
    "- Checking existing bug reports\n",
    "- Checking existing feature requests\n",
    "- Checking ongoing tickets\n",
    "- ... and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505efb75-04ad-4a25-888c-39265bcf666c",
   "metadata": {},
   "source": [
    "- Some ways of using CrewAI tools.\n",
    "\n",
    "```Python\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c73591-b6bb-4150-b946-ec46baf5ec39",
   "metadata": {},
   "source": [
    "- Instantiate a document scraper tool.\n",
    "- The tool will scrape a page (only 1 URL) of the CrewAI documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44c4873a-f07f-4d8d-b57e-51b96cea1a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_scrape_tool = ScrapeWebsiteTool(\n",
    "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83aca60-57b5-4e75-a9d2-9f4987bb5d68",
   "metadata": {},
   "source": [
    "##### Different Ways to Give Agents Tools\n",
    "\n",
    "- Agent Level: The Agent can use the Tool(s) on any Task it performs.\n",
    "- Task Level: The Agent will only use the Tool(s) when performing that specific Task.\n",
    "\n",
    "**Note**: Task Tools override the Agent Tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d824f240-660d-4282-8c9c-fdf3d1b01bd9",
   "metadata": {},
   "source": [
    "### Creating Tasks\n",
    "- You are passing the Tool on the Task Level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82bbf97a-fc26-4e27-8bd2-a69470bac032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inquiry_resolution = Task(\n",
    "    description=(\n",
    "        \"{customer} just reached out with a super important ask:\\n\"\n",
    "\t    \"{inquiry}\\n\\n\"\n",
    "        \"{person} from {customer} is the one that reached out. \"\n",
    "\t\t\"Make sure to use everything you know \"\n",
    "        \"to provide the best support possible.\"\n",
    "\t\t\"You must strive to provide a complete \"\n",
    "        \"and accurate response to the customer's inquiry.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "\t    \"A detailed, informative response to the \"\n",
    "        \"customer's inquiry that addresses \"\n",
    "        \"all aspects of their question.\\n\"\n",
    "        \"The response should include references \"\n",
    "        \"to everything you used to find the answer, \"\n",
    "        \"including external data or solutions. \"\n",
    "        \"Ensure the answer is complete, \"\n",
    "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
    "\t\t\"tone throughout.\"\n",
    "    ),\n",
    "\ttools=[docs_scrape_tool],\n",
    "    agent=support_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266426d-ae68-4a20-bf67-40638dbd7247",
   "metadata": {},
   "source": [
    "- `quality_assurance_review` is not using any Tool(s)\n",
    "- Here the QA Agent will only review the work of the Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b93fe6dc-0eed-40bb-9d11-90d9323c8eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quality_assurance_review = Task(\n",
    "    description=(\n",
    "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
    "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
    "\t\t\"high-quality standards expected for customer support.\\n\"\n",
    "        \"Verify that all parts of the customer's inquiry \"\n",
    "        \"have been addressed \"\n",
    "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
    "        \"Check for references and sources used to \"\n",
    "        \" find the information, \"\n",
    "\t\t\"ensuring the response is well-supported and \"\n",
    "        \"leaves no questions unanswered.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A final, detailed, and informative response \"\n",
    "        \"ready to be sent to the customer.\\n\"\n",
    "        \"This response should fully address the \"\n",
    "        \"customer's inquiry, incorporating all \"\n",
    "\t\t\"relevant feedback and improvements.\\n\"\n",
    "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
    "\t    \"but maintain a professional and friendly tone throughout.\"\n",
    "    ),\n",
    "    agent=support_quality_assurance_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2732f-a911-410d-801e-eeda6de70b27",
   "metadata": {},
   "source": [
    "### Creating the Crew\n",
    "\n",
    "#### Memory\n",
    "- Setting `memory=True` when putting the crew together enables Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e637bad8-5dd3-469d-a6d9-df721db27bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 10:21:28,034 - 139645887461184 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "  agents=[support_agent, support_quality_assurance_agent],\n",
    "  tasks=[inquiry_resolution, quality_assurance_review],\n",
    "  verbose=2,\n",
    "  memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891ed50-4790-411b-8833-fc9b6b90915e",
   "metadata": {},
   "source": [
    "### Running the Crew\n",
    "\n",
    "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video.\n",
    "\n",
    "#### Guardrails\n",
    "- By running the execution below, you can see that the agents and the responses are within the scope of what we expect from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "465a680d-d34c-4e5b-88d8-cbc16fce149b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Support Representative\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: DeepLearningAI just reached out with a super important ask:\n",
      "I need help with setting up a Crew and kicking it off, specifically how can I add memory to my crew? Can you provide guidance?\n",
      "\n",
      "Andrew Ng from DeepLearningAI is the one that reached out. Make sure to use everything you know to provide the best support possible.You must strive to provide a complete and accurate response to the customer's inquiry.\u001b[00m\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: fake. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepLearningAI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAndrew Ng\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you provide guidance?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/crew.py:252\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    254\u001b[0m     result, manager_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/crew.py:293\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_log_file:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_handler\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    290\u001b[0m         agent\u001b[38;5;241m=\u001b[39mrole, task\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mdescription, status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39masync_execution:\n\u001b[1;32m    295\u001b[0m     task_output \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/task.py:173\u001b[0m, in \u001b[0;36mTask.execute\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/task.py:182\u001b[0m, in \u001b[0;36mTask._execute\u001b[0;34m(self, agent, task, context, tools)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, task, context, tools):\n\u001b[0;32m--> 182\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     exported_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    191\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m    192\u001b[0m         exported_output\u001b[38;5;241m=\u001b[39mexported_output,\n\u001b[1;32m    193\u001b[0m         raw_output\u001b[38;5;241m=\u001b[39mresult,\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/agent.py:207\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39mmemory:\n\u001b[1;32m    202\u001b[0m     contextual_memory \u001b[38;5;241m=\u001b[39m ContextualMemory(\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_short_term_memory,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_long_term_memory,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_entity_memory,\n\u001b[1;32m    206\u001b[0m     )\n\u001b[0;32m--> 207\u001b[0m     memory \u001b[38;5;241m=\u001b[39m \u001b[43mcontextual_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_context_for_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m memory\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m         task_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi18n\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(memory\u001b[38;5;241m=\u001b[39mmemory)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/memory/contextual/contextual_memory.py:22\u001b[0m, in \u001b[0;36mContextualMemory.build_context_for_task\u001b[0;34m(self, task, context)\u001b[0m\n\u001b[1;32m     20\u001b[0m context \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_ltm_context(task\u001b[38;5;241m.\u001b[39mdescription))\n\u001b[0;32m---> 22\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_stm_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_entity_context(query))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, context))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/memory/contextual/contextual_memory.py:31\u001b[0m, in \u001b[0;36mContextualMemory._fetch_stm_context\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_stm_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, query) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Fetches recent relevant insights from STM related to the task's description and expected_output,\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    formatted as bullet points.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     stm_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     formatted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m stm_results])\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecent Insights:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mformatted_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stm_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/memory/short_term/short_term_memory.py:23\u001b[0m, in \u001b[0;36mShortTermMemory.search\u001b[0;34m(self, query, score_threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, score_threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.35\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/crewai/memory/storage/rag_storage.py:90\u001b[0m, in \u001b[0;36mRAGStorage.search\u001b[0;34m(self, query, limit, filter, score_threshold)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress_logging():\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         results \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39msearch(query, limit, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m)\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m\n\u001b[0;32m---> 90\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidDimensionException:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/embedchain/embedchain.py:653\u001b[0m, in \u001b[0;36mEmbedChain.search\u001b[0;34m(self, query, num_documents, where, raw_filter, namespace)\u001b[0m\n\u001b[1;32m    642\u001b[0m filter_criteria \u001b[38;5;241m=\u001b[39m raw_filter \u001b[38;5;28;01mif\u001b[39;00m raw_filter \u001b[38;5;28;01melse\u001b[39;00m where\n\u001b[1;32m    644\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_results\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_documents,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m     filter_type: filter_criteria,\n\u001b[1;32m    651\u001b[0m }\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;241m1\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/embedchain/vectordb/chroma.py:220\u001b[0m, in \u001b[0;36mChromaDB.query\u001b[0;34m(self, input_query, n_results, where, raw_filter, citations, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     where_clause \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_where_clause(where)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_clause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidDimensionException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDimensionException(\n\u001b[1;32m    229\u001b[0m         e\u001b[38;5;241m.\u001b[39mmessage()\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. This is commonly a side-effect when an embedding function, different from the one used to add the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m embeddings, is used to retrieve an embedding from the database.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/chromadb/api/models/Collection.py:327\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_query_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_texts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         valid_query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_query_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m         valid_query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mvalid_query_images)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/chromadb/api/models/Collection.py:633\u001b[0m, in \u001b[0;36mCollection._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.trychroma.com/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/chromadb/api/types.py:193\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[0;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/chromadb/utils/embedding_functions.py:188\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v1:\n\u001b[0;32m--> 188\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deployment_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: fake. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"customer\": \"DeepLearningAI\",\n",
    "    \"person\": \"Andrew Ng\",\n",
    "    \"inquiry\": \"I need help with setting up a Crew \"\n",
    "               \"and kicking it off, specifically \"\n",
    "               \"how can I add memory to my crew? \"\n",
    "               \"Can you provide guidance?\"\n",
    "}\n",
    "result = crew.kickoff(inputs=inputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7baf30-6cb1-4c98-b089-76ade39862f1",
   "metadata": {},
   "source": [
    "- Display the final result as Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a172def-6f91-4de0-9738-d5f41d94bea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
